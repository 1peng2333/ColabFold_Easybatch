{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AlphaFold2_complexes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2_complexes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "#AlphaFold2_complexes\n",
        "\n",
        "Credit to Minkyung Baek @minkbaek and Yoshitaka Moriwaki @Ag_smith for showing it works in alphafold2.\n",
        "- https://twitter.com/minkbaek/status/1417538291709071362\n",
        "- https://twitter.com/Ag_smith/status/1417063635000598528\n",
        "\n",
        "- [script](https://github.com/RosettaCommons/RoseTTAFold/blob/main/example/complex_modeling/make_joint_MSA_bacterial.py) from rosettafold for paired alignment generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOblAo-xetgx",
        "cellView": "form"
      },
      "source": [
        "#@title Input protein sequences\n",
        "from google.colab import files\n",
        "import os\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "query_sequence_a = 'AVLKIIQGALDTRELLKAYQEEACAKNFGAFCVFVGIVRKEDNIQGLSFDIYEALLKTWFEKWHHKAKDLGVVLKMAHSLGDVLIGQSSFLCVSMGKNRKNALELYENFIEDFKHNAPIWKYDLIHNKRIYAKERSHPLKGSGLLA' #@param {type:\"string\"}\n",
        "query_sequence_a = \"\".join(query_sequence_a.split())\n",
        "query_sequence_a = re.sub(r'[^a-zA-Z]','', query_sequence_a).upper()\n",
        "\n",
        "query_sequence_b = 'MMVEVRFFGPIKEENFFIKANDLKELRAILQEKEGLKEWLGVCAIALNDHLIDNLNTPLKDGDVISLLPPVCGG' #@param {type:\"string\"}\n",
        "query_sequence_b = \"\".join(query_sequence_b.split())\n",
        "query_sequence_b = re.sub(r'[^a-zA-Z]','', query_sequence_b).upper()\n",
        "\n",
        "query_sequence = query_sequence_a + query_sequence_b\n",
        "\n",
        "jobname = '3RPF' #@param {type:\"string\"}\n",
        "jobname = \"\".join(jobname.split())\n",
        "jobname = re.sub(r'\\W+', '', jobname)\n",
        "\n",
        "with open(f\"{jobname}_a.fasta\", \"w\") as text_file:\n",
        "    text_file.write(\">1\\n%s\" % query_sequence_a)\n",
        "\n",
        "with open(f\"{jobname}_b.fasta\", \"w\") as text_file:\n",
        "    text_file.write(\">1\\n%s\" % query_sequence_b)\n",
        "\n",
        "# number of models to use\n",
        "#@markdown ---\n",
        "#@markdown ### Advanced settings\n",
        "num_models = 1 #@param [1,2,3,4,5] {type:\"raw\"}\n",
        "msa_mode = \"MMseqs2\" #@param [\"MMseqs2\",\"single_sequence\"]\n",
        "use_msa = True if msa_mode == \"MMseqs2\" else False\n",
        "pair_msa = True #@param {type:\"boolean\"}\n",
        "#@markdown Note: for homodimers, might help to disable pair_msa\n",
        "\n",
        "#@markdown ---\n",
        "with open(f\"{jobname}.log\", \"w\") as text_file:\n",
        "    text_file.write(\"num_models=%s\\n\" % num_models)\n",
        "    text_file.write(\"use_msa=%s\\n\" % use_msa)\n",
        "    text_file.write(\"msa_mode=%s\\n\" % msa_mode)\n",
        "    text_file.write(\"pair_msa=%s\\n\" % pair_msa)\n",
        "\n",
        "# decide which a3m to use\n",
        "if use_msa:\n",
        "  a3m_file_a = f\"{jobname}_a.a3m\"\n",
        "  a3m_file_b = f\"{jobname}_b.a3m\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iccGdbe_Pmt9",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "%%bash -s $use_msa\n",
        "USE_MSA=$1\n",
        "if [ ! -f AF2_READY ]; then\n",
        "\n",
        "  # install dependencies\n",
        "  pip -q install biopython\n",
        "  pip -q install dm-haiku\n",
        "  pip -q install ml-collections\n",
        "  pip -q install py3Dmol\n",
        "\n",
        "  # download model\n",
        "  if [ ! -d \"alphafold/\" ]; then\n",
        "    git clone https://github.com/deepmind/alphafold.git --quiet\n",
        "    mv alphafold alphafold_\n",
        "    mv alphafold_/alphafold .\n",
        "    # remove \"END\" from PDBs, otherwise biopython complains\n",
        "    sed -i \"s/pdb_lines.append('END')//\" /content/alphafold/common/protein.py\n",
        "    sed -i \"s/pdb_lines.append('ENDMDL')//\" /content/alphafold/common/protein.py\n",
        "  fi\n",
        "\n",
        "  # download model params (~1 min)\n",
        "  if [ ! -d \"params/\" ]; then\n",
        "    wget -qnc https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar\n",
        "    mkdir params\n",
        "    tar -xf alphafold_params_2021-07-14.tar -C params/\n",
        "    rm alphafold_params_2021-07-14.tar\n",
        "  fi\n",
        "  touch AF2_READY\n",
        "fi\n",
        "# download libraries for interfacing with MMseqs2 API\n",
        "if [ ${USE_MSA} == \"True\" ]; then\n",
        "  if [ ! -f MMSEQ2_READY ]; then\n",
        "    apt-get -qq -y update 2>&1 1>/dev/null\n",
        "    apt-get -qq -y install jq curl zlib1g gawk 2>&1 1>/dev/null\n",
        "    touch MMSEQ2_READY\n",
        "  fi\n",
        "fi"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9tUpDaikPC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "16b84ea3-f2a4-483f-b87f-0b1e056e689f"
      },
      "source": [
        "#@title Call MMseqs2 to get MSA/templates\n",
        "%%bash -s $use_msa $jobname\n",
        "USE_MSA=$1\n",
        "JOBNAME=$2\n",
        "if [ ${USE_MSA} == \"True\" ]; then\n",
        "  for C in \"a\" \"b\"\n",
        "  do\n",
        "    if [ ! -f ${JOBNAME}_${C}.mmseqs2.tar.gz ]; then\n",
        "      # query MMseqs2 webserver\n",
        "      echo \"submitting job\"\n",
        "      ID=$(curl -s -F q=@${JOBNAME}_${C}.fasta -F mode=all https://a3m.mmseqs.com/ticket/msa | jq -r '.id')\n",
        "      STATUS=$(curl -s https://a3m.mmseqs.com/ticket/${ID} | jq -r '.status')\n",
        "      while [ \"${STATUS}\" == \"RUNNING\" ]; do\n",
        "        STATUS=$(curl -s https://a3m.mmseqs.com/ticket/${ID} | jq -r '.status')\n",
        "        sleep 1\n",
        "      done\n",
        "      if [ \"${STATUS}\" == \"COMPLETE\" ]; then\n",
        "        curl -s https://a3m.mmseqs.com/result/download/${ID} > ${JOBNAME}_${C}.mmseqs2.tar.gz\n",
        "        tar xzf ${JOBNAME}_${C}.mmseqs2.tar.gz\n",
        "        tr -d '\\000' < uniref.a3m > ${JOBNAME}_${C}.a3m\n",
        "        rm uniref.a3m\n",
        "        mv pdb70.m8 ${JOBNAME}_${C}.m8\n",
        "      else\n",
        "        echo \"MMseqs2 server did not return a valid result.\"\n",
        "        cp ${JOBNAME}_${C}.fasta ${JOBNAME}_${C}.a3m\n",
        "      fi\n",
        "    fi\n",
        "    if [ ${USE_MSA} == \"True\" ]; then\n",
        "      echo \"Found $(grep -c \">\" ${JOBNAME}_${C}.a3m) sequences (after redundacy filtering)\"\n",
        "    fi\n",
        "  done\n",
        "fi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "submitting job\n",
            "Found 225 sequences (after redundacy filtering)\n",
            "submitting job\n",
            "Found 232 sequences (after redundacy filtering)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPWfhGssZdTb",
        "cellView": "form"
      },
      "source": [
        "#@title Import libraries and setup model\n",
        "# setup the model\n",
        "if \"model\" not in dir():\n",
        "\n",
        "  # hiding warning messages\n",
        "  import warnings\n",
        "  from absl import logging\n",
        "  import os\n",
        "  import tensorflow as tf\n",
        "  warnings.filterwarnings('ignore')\n",
        "  logging.set_verbosity(\"error\")\n",
        "  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "  tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "  import sys\n",
        "  import numpy as np\n",
        "  import pickle\n",
        "  from string import ascii_uppercase\n",
        "  from alphafold.common import protein\n",
        "  from alphafold.data import pipeline\n",
        "  from alphafold.data import templates\n",
        "  from alphafold.model import data\n",
        "  from alphafold.model import config\n",
        "  from alphafold.model import model\n",
        "  from alphafold.data.tools import hhsearch\n",
        "\n",
        "  # plotting libraries\n",
        "  import py3Dmol\n",
        "  import matplotlib.pyplot as plt\n",
        "  import ipywidgets\n",
        "  from ipywidgets import interact, fixed\n",
        "\n",
        "def mk_mock_template(query_sequence):\n",
        "  # since alphafold's model requires a template input\n",
        "  # we create a blank example w/ zero input, confidence -1\n",
        "  ln = len(query_sequence)\n",
        "  output_templates_sequence = \"-\"*ln\n",
        "  output_confidence_scores = np.full(ln,-1)\n",
        "  templates_all_atom_positions = np.zeros((ln, templates.residue_constants.atom_type_num, 3))\n",
        "  templates_all_atom_masks = np.zeros((ln, templates.residue_constants.atom_type_num))\n",
        "  templates_aatype = templates.residue_constants.sequence_to_onehot(output_templates_sequence,\n",
        "                                                                    templates.residue_constants.HHBLITS_AA_TO_ID)\n",
        "  template_features = {'template_all_atom_positions': templates_all_atom_positions[None],\n",
        "                       'template_all_atom_masks': templates_all_atom_masks[None],\n",
        "                       'template_sequence': [f'none'.encode()],\n",
        "                       'template_aatype': np.array(templates_aatype)[None],\n",
        "                       'template_confidence_scores': output_confidence_scores[None],\n",
        "                       'template_domain_names': [f'none'.encode()],\n",
        "                       'template_release_date': [f'none'.encode()]}\n",
        "  return template_features\n",
        "\n",
        "def set_bfactor(pdb_filename, bfac, idx_res, chains):\n",
        "  I = open(pdb_filename,\"r\").readlines()\n",
        "  O = open(pdb_filename,\"w\")\n",
        "  for line in I:\n",
        "    if line[0:6] == \"ATOM  \":\n",
        "      seq_id = int(line[23:26].strip()) - 1\n",
        "      seq_id = np.where(idx_res == seq_id)[0][0]\n",
        "      O.write(f\"{line[:21]}{chains[seq_id]}{line[22:60]}{bfac[seq_id]:6.2f}{line[66:]}\")\n",
        "  O.close()\n",
        "\n",
        "def predict_structure(prefix, feature_dict, Ls, random_seed=0):  \n",
        "  \"\"\"Predicts structure using AlphaFold for the given sequence.\"\"\"\n",
        "\n",
        "  # Minkyung's code\n",
        "  # add big enough number to residue index to indicate chain breaks\n",
        "  idx_res = feature_dict['residue_index']\n",
        "  L_prev = 0\n",
        "  # Ls: number of residues in each chain\n",
        "  for L_i in Ls[:-1]:\n",
        "      idx_res[L_prev+L_i:] += 200\n",
        "      L_prev += L_i  \n",
        "  chains = list(\"\".join([ascii_uppercase[n]*L for n,L in enumerate(Ls)]))\n",
        "\n",
        "  feature_dict['residue_index'] = idx_res\n",
        "\n",
        "  # Run the models.\n",
        "  plddts = []\n",
        "  unrelaxed_pdb_lines = []\n",
        "  relaxed_pdb_lines = []\n",
        "\n",
        "  for model_name, params in model_params.items():\n",
        "    print(f\"running {model_name}\")\n",
        "    # swap params to avoid recompiling\n",
        "    # note: models 1,2 have diff number of params compared to models 3,4,5\n",
        "    if any(str(m) in model_name for m in [1,2]): model_runner = model_runner_1\n",
        "    if any(str(m) in model_name for m in [3,4,5]): model_runner = model_runner_3\n",
        "    model_runner.params = params\n",
        "    \n",
        "    processed_feature_dict = model_runner.process_features(feature_dict, random_seed=random_seed)\n",
        "    prediction_result = model_runner.predict(processed_feature_dict)\n",
        "    unrelaxed_protein = protein.from_prediction(processed_feature_dict,prediction_result)\n",
        "    unrelaxed_pdb_lines.append(protein.to_pdb(unrelaxed_protein))\n",
        "    plddts.append(prediction_result['plddt'])\n",
        "\n",
        "  # rerank models based on predicted lddt\n",
        "  lddt_rank = np.mean(plddts,-1).argsort()[::-1]\n",
        "  plddts_ranked = {}\n",
        "  for n,r in enumerate(lddt_rank):\n",
        "    print(f\"model_{n+1} {np.mean(plddts[r])}\")\n",
        "\n",
        "    unrelaxed_pdb_path = f'{prefix}_unrelaxed_model_{n+1}.pdb'    \n",
        "    with open(unrelaxed_pdb_path, 'w') as f: f.write(unrelaxed_pdb_lines[r])\n",
        "    set_bfactor(unrelaxed_pdb_path,plddts[r]/100, idx_res, chains)\n",
        "\n",
        "    plddts_ranked[f\"model_{n+1}\"] = plddts[r]\n",
        "\n",
        "  return plddts_ranked\n",
        "\n",
        "##################################\n",
        "# CODE FROM MINKYUNG/ROSETTAFOLD\n",
        "##################################\n",
        "def read_a3m(fn):\n",
        "    '''parse an a3m files as a dictionary {label->sequence}'''\n",
        "    seq = []\n",
        "    lab = []\n",
        "    is_first = True\n",
        "    for line in open(fn, \"r\"):\n",
        "        if line[0] == '>':\n",
        "            label = line.strip()[1:]\n",
        "            is_incl = True\n",
        "            if is_first: # include first sequence (query)\n",
        "                is_first = False\n",
        "                lab.append(label)\n",
        "                continue\n",
        "            if \"UniRef\" in label:\n",
        "                code = label.split()[0].split('_')[-1]\n",
        "                if code.startswith(\"UPI\"): # UniParc identifier -- exclude\n",
        "                    is_incl = False\n",
        "                    continue\n",
        "            elif label.startswith(\"tr|\"):\n",
        "                code = label.split('|')[1]\n",
        "            else:\n",
        "                is_incl = False\n",
        "                continue\n",
        "            lab.append(code)\n",
        "        else:\n",
        "            if is_incl:\n",
        "                seq.append(line.rstrip())\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    return seq, lab\n",
        "\n",
        "# https://www.uniprot.org/help/accession_numbers\n",
        "def uni2idx(ids):\n",
        "    '''convert uniprot ids into integers according to the structure\n",
        "    of uniprot accession numbers'''\n",
        "    ids2 = [i.split(\"-\")[0] for i in ids]\n",
        "    ids2 = [i+'AAA0' if len(i)==6 else i for i in ids2]\n",
        "    arr = np.array([list(s) for s in ids2], dtype='|S1').view(np.uint8)\n",
        "\n",
        "    for i in [1,5,9]:\n",
        "        arr[:,i] -= ord('0')\n",
        "\n",
        "    arr[arr>=ord('A')] -= ord('A')\n",
        "    arr[arr>=ord('0')] -= ord('0')-26\n",
        "\n",
        "    arr[:,0][arr[:,0]>ord('Q')-ord('A')] -= 3\n",
        "\n",
        "    arr = arr.astype(np.int64)\n",
        "\n",
        "    coef = np.array([23,10,26,36,36,10,26,36,36,1], dtype=np.int64)\n",
        "    coef = np.tile(coef[None,:],[len(ids),1])\n",
        "\n",
        "    c1 = [i for i,id_ in enumerate(ids) if id_[0] in 'OPQ' and len(id_)==6]\n",
        "    c2 = [i for i,id_ in enumerate(ids) if id_[0] not in 'OPQ' and len(id_)==6]\n",
        "\n",
        "    coef[c1] = np.array([3, 10,36,36,36,1,1,1,1,1])\n",
        "    coef[c2] = np.array([23,10,26,36,36,1,1,1,1,1])\n",
        "\n",
        "    for i in range(1,10):\n",
        "        coef[:,-i-1] *= coef[:,-i]\n",
        "\n",
        "    return np.sum(arr*coef,axis=-1)\n",
        "\n",
        "##########################\n",
        "# DATABASE\n",
        "##########################\n",
        "if \"model_params\" not in dir(): model_params = {}\n",
        "for model_name in [\"model_1\",\"model_2\",\"model_3\",\"model_4\",\"model_5\"][:num_models]:\n",
        "  if model_name not in model_params:\n",
        "    model_config = config.model_config(model_name)\n",
        "    model_config.data.eval.num_ensemble = 1\n",
        "    model_params[model_name] = data.get_model_haiku_params(model_name=model_name, data_dir=\".\")\n",
        "    if model_name == \"model_1\":\n",
        "      model_runner_1 = model.RunModel(model_config, model_params[model_name])\n",
        "    if model_name == \"model_3\":\n",
        "      model_runner_3 = model.RunModel(model_config, model_params[model_name])\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUYApPElB30u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ae8acb3e-f5f6-4b5c-aa8d-237ba7ad2915"
      },
      "source": [
        "#@title Gather input features, predict structure\n",
        "\n",
        "Ls = [len(query_sequence_a),len(query_sequence_b)]\n",
        "msas = []\n",
        "deletion_matrices = []\n",
        "\n",
        "# parse MSA\n",
        "if use_msa:\n",
        "  \n",
        "  # MSA_AB\n",
        "  if pair_msa:\n",
        "    ###########################################################################\n",
        "    # CODE FROM MINKYUNG/ROSETTAFOLD\n",
        "    ###########################################################################\n",
        "    msa1, lab1 = read_a3m(a3m_file_a)\n",
        "    msa2, lab2 = read_a3m(a3m_file_b)\n",
        "    if len(lab1) > 1 and len(lab2) > 1:\n",
        "      # convert uniprot ids into integers\n",
        "      hash1 = uni2idx(lab1[1:])\n",
        "      hash2 = uni2idx(lab2[1:])\n",
        "\n",
        "      # find pairs of uniprot ids which are separated by at most 10\n",
        "      idx1, idx2 = np.where(np.abs(hash1[:,None]-hash2[None,:]) < 10)\n",
        "      if idx1.shape[0] > 0:\n",
        "        a3m_lines = ['>query\\n%s%s\\n'%(msa1[0],msa2[0])]\n",
        "        for i,j in zip(idx1,idx2):\n",
        "          a3m_lines.append(\">%s_%s\\n%s%s\\n\"%(lab1[i+1],lab2[j+1],msa1[i+1],msa2[j+1]))\n",
        "        \n",
        "        msa, deletion_matrix = pipeline.parsers.parse_a3m(\"\".join(a3m_lines))\n",
        "        msas.append(msa)\n",
        "        deletion_matrices.append(deletion_matrix)\n",
        "\n",
        "        print(\"pairs found:\",len(msa))\n",
        "\n",
        "  # MSA_A\n",
        "  a3m_lines = \"\".join(open(a3m_file_a,\"r\").readlines())\n",
        "  msa, deletion_matrix = pipeline.parsers.parse_a3m(a3m_lines)\n",
        "  msas.append([seq+\"-\"*Ls[1] for seq in msa])\n",
        "  deletion_matrices.append([mtx+[0]*Ls[1] for mtx in deletion_matrix])\n",
        "\n",
        "  # MSA_B\n",
        "  a3m_lines = \"\".join(open(a3m_file_b,\"r\").readlines())\n",
        "  msa, deletion_matrix = pipeline.parsers.parse_a3m(a3m_lines)\n",
        "  msas.append([\"-\"*Ls[0]+seq for seq in msa])\n",
        "  deletion_matrices.append([[0]*Ls[0]+mtx for mtx in deletion_matrix])\n",
        "else:\n",
        "  msas.append([query_sequence])\n",
        "  deletion_matrices.append([[0]*len(query_sequence)])\n",
        "\n",
        "# gather features\n",
        "feature_dict = {\n",
        "    **pipeline.make_sequence_features(sequence=query_sequence,\n",
        "                                      description=\"none\",\n",
        "                                      num_res=len(query_sequence)),\n",
        "    **pipeline.make_msa_features(msas=msas, deletion_matrices=deletion_matrices),\n",
        "    **mk_mock_template(query_sequence)\n",
        "}\n",
        "plddts = predict_structure(jobname, feature_dict, Ls=Ls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pairs found: 16\n",
            "running model_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exKwNxDxF7IO",
        "cellView": "form"
      },
      "source": [
        "#@title Plot lDDT per residue\n",
        "# confidence per position\n",
        "plt.figure(dpi=100)\n",
        "for model_name,value in plddts.items():\n",
        "  plt.plot(value,label=model_name)\n",
        "plt.legend()\n",
        "plt.ylim(0,100)\n",
        "plt.ylabel(\"predicted lDDT\")\n",
        "plt.xlabel(\"positions\")\n",
        "plt.savefig(jobname+\"_lDDT.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xbvRNrwnJqj",
        "cellView": "form"
      },
      "source": [
        "#@title Plot Number of Sequences per Position\n",
        "# confidence per position\n",
        "plt.figure(dpi=100)\n",
        "plt.plot((feature_dict[\"msa\"] != 21).sum(0))\n",
        "plt.xlabel(\"positions\")\n",
        "plt.ylabel(\"number of sequences\")\n",
        "plt.savefig(jobname+\"_msa_coverage.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-rPnOXdjf18",
        "cellView": "form"
      },
      "source": [
        "#@title Show 3D structure\n",
        "def show_pdb(model_name,\n",
        "             show_sidechains=False,\n",
        "             show_mainchain=False,\n",
        "             color=\"chain\"):\n",
        "\n",
        "  def mainchain(p, color=\"white\", model=0):\n",
        "    BB = ['C','O','N','CA']\n",
        "    p.addStyle({\"model\":model,'atom':BB},\n",
        "                       {'stick':{'colorscheme':f\"{color}Carbon\",'radius':0.4}})\n",
        "\n",
        "  def sidechain(p, model=0):\n",
        "    HP = [\"ALA\",\"GLY\",\"VAL\",\"ILE\",\"LEU\",\"PHE\",\"MET\",\"PRO\",\"TRP\",\"CYS\",\"TYR\"]\n",
        "    BB = ['C','O','N']\n",
        "    p.addStyle({\"model\":model,'and':[{'resn':HP},{'atom':BB,'invert':True}]},\n",
        "              {'stick':{'colorscheme':\"yellowCarbon\",'radius':0.4}})\n",
        "    p.addStyle({\"model\":model,'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "              {'sphere':{'colorscheme':\"yellowCarbon\",'radius':0.4}})\n",
        "    p.addStyle({\"model\":model,'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "              {'stick':{'colorscheme':\"yellowCarbon\",'radius':0.4}})  \n",
        "    p.addStyle({\"model\":model,'and':[{'resn':HP,'invert':True},{'atom':BB,'invert':True}]},\n",
        "              {'stick':{'colorscheme':\"whiteCarbon\",'radius':0.4}})\n",
        "\n",
        "  pdb_filename = f\"{jobname}_unrelaxed_{model_name}.pdb\"\n",
        "\n",
        "  p = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "  p.addModel(open(pdb_filename,'r').read(),'pdb')\n",
        "  if color == \"lDDT\":\n",
        "    p.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':0,'max':1}}})\n",
        "  elif color == \"rainbow\":\n",
        "    p.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "  else:\n",
        "    p.setStyle({'chain':\"A\"},{'cartoon': {'color':'lime'}})\n",
        "    p.setStyle({'chain':\"B\"},{'cartoon': {'color':'cyan'}})\n",
        "\n",
        "  if show_sidechains: sidechain(p)\n",
        "  if show_mainchain: mainchain(p)\n",
        "  p.zoomTo()\n",
        "  return p.show()\n",
        "\n",
        "interact(show_pdb,\n",
        "         model_name=ipywidgets.Dropdown(options=model_params.keys(), value='model_1'),\n",
        "         show_sidechains=ipywidgets.Checkbox(value=False),\n",
        "         show_mainchain=ipywidgets.Checkbox(value=False),\n",
        "         color=ipywidgets.Dropdown(options=['chain', 'rainbow', 'lDDT'], value='chain'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33g5IIegij5R",
        "cellView": "form"
      },
      "source": [
        "#@title Package and download results\n",
        "!zip -FSr $jobname\".result.zip\" $jobname\".log\" $jobname\"_msa_coverage.png\" $jobname\"_\"*\"relaxed_model_\"*\".pdb\" $jobname\"_lDDT.png\"\n",
        "files.download(f\"{jobname}.result.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP1m6jI7BgMT"
      },
      "source": [
        "# Instructions\n",
        "- If you having issues downloading results, try disable adblocker and run the last cell again. If that fails click on the little folder icon to the left, navigate to file:`jobname.result.zip`, right-click and select \"download\"."
      ]
    }
  ]
}